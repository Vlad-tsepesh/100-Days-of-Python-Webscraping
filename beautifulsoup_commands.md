# BeautifulSoup Top Commands Cheat Sheet

A concise list of the most used **BeautifulSoup** commands and properties, formatted for quick lookup and practical usage.

---

## ðŸŒ³ Core Object & Initialization

1. `BeautifulSoup(html, parser)` â€“ create a soup object from HTML/XML
2. `.prettify()` â€“ format the parse tree with indentation
3. `.encode(...)` / `.decode(...)` â€“ encode/decode with formatting options

---

## ðŸ” Searching & Filtering

4. `.find(name, attrs, ...)` â€“ returns the first matching tag
5. `.find_all(name, attrs, limit=â€¦)` â€“ returns all matching tags
6. `.select(selector)` â€“ use CSS selectors (e.g. `.content p#intro`)
7. `.find_parent(...)` / `.find_parents(...)` â€“ find ancestor tags
8. `.find_next_sibling(...)` / `.find_previous_sibling(...)` â€“ get adjacent sibling
9. `.find_next_siblings(...)` / `.find_previous_siblings(...)` â€“ all adjacent siblings
10. `.find_next(...)` / `.find_previous(...)` â€“ next/prev in document order
11. `.find_all_next(...)` / `.find_all_previous(...)` â€“ all following/preceding elements
12. Use `text=` in `.find_all(...)` â€“ filter by inner text
13. Use `attrs={...}` â€“ filter by attributes dict
14. Use regex, list, function, or `True` in tag search filters

---

## ðŸš¶ Traversal: Tree Navigation

15. `.contents` â€“ list of direct children
16. `.children` â€“ iterator over direct children
17. `.descendants` â€“ iterator over all descendants
18. `.string` â€“ if the tag has one direct string child
19. `.strings` â€“ all descendant strings (including whitespace)
20. `.stripped_strings` â€“ all descendant strings (no whitespace)
21. `.parent` â€“ direct parent
22. `.parents` â€“ generator of all ancestors
23. `.next_sibling` / `.previous_sibling` â€“ adjacent elements
24. `.next_siblings` / `.previous_siblings` â€“ all siblings after/before
25. `.next_element` / `.previous_element` â€“ next/prev in doc order
26. `.next_elements` / `.previous_elements` â€“ all following/preceding nodes

---

## ðŸ’¬ Accessing Text & Attributes

27. `.get_text(separator, strip)` â€“ combined text with options
28. `.text` â€“ shorthand for `.get_text()`
29. Attribute access â€“ `tag['href']`, `tag.get('class')`, etc.

---

## âœï¸ Modifying the Tree

30. `.append(new)` â€“ add child tag
31. `.extend([...])` â€“ add multiple children
32. `.new_tag(name, **attrs)` â€“ create a new tag
33. `.insert(position, new_tag)` â€“ insert child at index
34. `.insert_before(...)` / `.insert_after(...)` â€“ insert near current
35. `.clear()` â€“ remove all children
36. `.extract()` â€“ remove this tag and return it
37. `.decompose()` â€“ completely destroy tag and contents
38. `.replace_with(new)` â€“ replace tag with another
39. `.wrap(new_tag)` â€“ wrap element in another tag
40. `.unwrap()` â€“ remove current tag, preserve children
41. `.smooth()` â€“ normalize whitespace and formatting
42. `.replace_with()` â€“ same tag replacement shortcut
43. Create and insert tag together: `.insert_*` and `.new_tag`

---

## ðŸ§° Diagnostics & Utilities

44. `diagnose(data)` â€“ inspect HTML to detect parser issues
45. `.get_text(strip=True)` â€“ get cleaned text from element
46. `.prettify()` â€“ format output (useful for inspection)

---

## ðŸ“œ Realâ€‘World Usage Example

```python
from bs4 import BeautifulSoup
import requests

html = requests.get(url).text
soup = BeautifulSoup(html, 'html.parser')
main = soup.find('div', class_='main')
links = main.find_all('a')

for a in links:
    print(a.get_text(strip=True), a['href'])
```

---

## âœ… Recap Summary

| Group        | Commands Count |
| ------------ | -------------- |
| Core & init  | \~3            |
| Searching    | \~11           |
| Traversal    | \~12           |
| Text & attrs | \~3            |
| Modify tree  | \~13           |
| Diagnostics  | \~3            |
| **Total**    | **\~45+**      |

---

> ðŸ“Œ Use these commands in real-world scraping, cleaning, and parsing workflows. Focus on `find`, `select`, `get_text`, and traversal for 90% of your use cases.

---

*Updated August 2025 â€“ compiled by ChatGPT based on BeautifulSoup documentation and usage in the field.*

